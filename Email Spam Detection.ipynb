{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1N9Mpfdvr5EfHHU_s0EBB3Ig9v3Pt7L-Z",
      "authorship_tag": "ABX9TyNiIaQ0fqrQjuW5EyzSohBe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Velmani06/Calculator/blob/main/Email%20Spam%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKkfgf0siVdD",
        "outputId": "e27e529e-836b-4e5b-f891-76a5fe6ec4f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1044/1044\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 54ms/step - accuracy: 0.8718 - loss: 0.3643 - val_accuracy: 0.9852 - val_loss: 0.0480\n",
            "Epoch 2/10\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/combined_data.csv')  # Replace with the actual path\n",
        "\n",
        "# Preprocessing the dataset\n",
        "# We are now using 'label' for target and 'text' for the email content\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "# Splitting data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to numerical form using TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Convert to dense arrays for TensorFlow input\n",
        "X_train_tfidf = X_train_tfidf.toarray()\n",
        "X_test_tfidf = X_test_tfidf.toarray()\n",
        "\n",
        "# Convert target labels to integer numpy arrays\n",
        "y_train = np.array(y_train).astype('int')\n",
        "y_test = np.array(y_test).astype('int')\n",
        "\n",
        "# Calculate class weights to handle imbalance\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Build the TensorFlow model with an Input layer\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(5000,)),  # Explicit input layer\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with class weights\n",
        "history = model.fit(X_train_tfidf, y_train, epochs=10, batch_size=64,\n",
        "                    validation_data=(X_test_tfidf, y_test), class_weight=class_weights)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Predicting the test set with a threshold of 0.5\n",
        "y_pred = (model.predict(X_test_tfidf) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Confusion Matrix and Classification Report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:\\n', cm)\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot Confusion Matrix Heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Plotting accuracy and loss during training\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusted Prediction Function with Threshold Control\n",
        "def classify_email(threshold=0.5):\n",
        "    while True:\n",
        "        email_input = input(\"\\nEnter an email to classify (or type 'exit' to stop):\\n\")\n",
        "        if email_input.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Convert the input email to TF-IDF features\n",
        "        email_tfidf = vectorizer.transform([email_input]).toarray()\n",
        "\n",
        "        # Predict whether the email is spam or not using the adjustable threshold\n",
        "        prediction = model.predict(email_tfidf)\n",
        "        result = 'Spam' if prediction > threshold else 'Ham'\n",
        "\n",
        "        print(f\"\\nPrediction: {result}\")\n",
        "\n",
        "# Call the classify_email function for live input\n",
        "classify_email(threshold=0.4)  # Example of using a custom threshold of 0.4\n"
      ],
      "metadata": {
        "id": "qCvqSyt7ivtf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}